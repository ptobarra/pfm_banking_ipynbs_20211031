{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb04bd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from pandas import read_excel, date_range, DatetimeIndex, DataFrame, to_numeric, concat, to_datetime\n",
    "from pandas.plotting import lag_plot, autocorrelation_plot\n",
    "from pandas.tseries.offsets import DateOffset, MonthEnd, MonthBegin\n",
    "\n",
    "import numpy\n",
    "from numpy import logical_not\n",
    "\n",
    "import statistics\n",
    "import dateutil.relativedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "import fbprophet\n",
    "from prophet import Prophet\n",
    "\n",
    "import calendar\n",
    "from calendar import monthrange\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8abc53a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14ef5254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nPedro Tobarra 20210902:\\nModificación del notebook '20210608 supermercados version ide v00.ipynb' para meter el código en una función \\nde python que luego pueda ser implementada en un fichero '.py' para su integración con el backend del PFM\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pedro Tobarra 20210902:\n",
    "Modificación del notebook '20210608 supermercados version ide v00.ipynb' para meter el código en una función \n",
    "de python que luego pueda ser implementada en un fichero '.py' para su integración con el backend del PFM\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d06bdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# esto no va en produccion\n",
    "\n",
    "# cambiamos el valor de estos 4 parametros para que nos muestre dataframes sin truncarlos\n",
    "pandas.set_option('display.max_rows', 12)\n",
    "# pandas.set_option('display.max_rows', None)\n",
    "pandas.set_option('display.max_columns', None)\n",
    "pandas.set_option('display.width', None)\n",
    "pandas.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d06ecaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha transacción</th>\n",
       "      <th>Importe</th>\n",
       "      <th>ID Categoría</th>\n",
       "      <th>Nombre categoría</th>\n",
       "      <th>Nivel categoría</th>\n",
       "      <th>iD categoría padre</th>\n",
       "      <th>Nombre categoría padre</th>\n",
       "      <th>Proveedor</th>\n",
       "      <th>Marca</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Financiero</th>\n",
       "      <th>Transferencia</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>ID</th>\n",
       "      <th>BALANCE</th>\n",
       "      <th>BALANCE_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>-1.20</td>\n",
       "      <td>84.0</td>\n",
       "      <td>parking_84</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>vehiculos_5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>249236.0</td>\n",
       "      <td>1478.98</td>\n",
       "      <td>2020-07-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>-4.50</td>\n",
       "      <td>117.0</td>\n",
       "      <td>regalos_celebraciones_117</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>gastos_personales_8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>-13.53</td>\n",
       "      <td>70.0</td>\n",
       "      <td>supermercados_70</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>alimentacion_4</td>\n",
       "      <td>SPAR</td>\n",
       "      <td>SPAR</td>\n",
       "      <td>Supermercados</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>-51.40</td>\n",
       "      <td>222.0</td>\n",
       "      <td>adsl_222</td>\n",
       "      <td>3.0</td>\n",
       "      <td>521.0</td>\n",
       "      <td>Comunicaciones y TV</td>\n",
       "      <td>Jazz Telecom</td>\n",
       "      <td>Jazztel</td>\n",
       "      <td>Compañías telecomunicaciones</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>-11.00</td>\n",
       "      <td>70.0</td>\n",
       "      <td>supermercados_70</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>alimentacion_4</td>\n",
       "      <td>Mercadona</td>\n",
       "      <td>Mercadona</td>\n",
       "      <td>Supermercados</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>2016-09-05</td>\n",
       "      <td>1533.02</td>\n",
       "      <td>18.0</td>\n",
       "      <td>retribucion_liquida_18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>Nómina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>2016-09-05</td>\n",
       "      <td>-617.47</td>\n",
       "      <td>126.0</td>\n",
       "      <td>liquidacion_tarjeta_126</td>\n",
       "      <td>3.0</td>\n",
       "      <td>478.0</td>\n",
       "      <td>tarjetas_credito_478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>2016-09-05</td>\n",
       "      <td>-138.08</td>\n",
       "      <td>125.0</td>\n",
       "      <td>cuotas_125</td>\n",
       "      <td>3.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>otros_pasivos_127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>-32.22</td>\n",
       "      <td>90.0</td>\n",
       "      <td>seguro_salud_90</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>salud_6</td>\n",
       "      <td>Sanitas S.A. de Seguros</td>\n",
       "      <td>Sanitas</td>\n",
       "      <td>Seguros de salud</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>-33.00</td>\n",
       "      <td>434.0</td>\n",
       "      <td>cuotas_434</td>\n",
       "      <td>3.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>deportes_115</td>\n",
       "      <td>Royal Sport Center</td>\n",
       "      <td>Royal Sport Center</td>\n",
       "      <td>Clubs deportivos</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1487 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Fecha transacción  Importe  ID Categoría           Nombre categoría  \\\n",
       "0           2020-07-24    -1.20          84.0                 parking_84   \n",
       "1           2020-07-23    -4.50         117.0  regalos_celebraciones_117   \n",
       "2           2020-07-23   -13.53          70.0           supermercados_70   \n",
       "3           2020-07-22   -51.40         222.0                   adsl_222   \n",
       "4           2020-07-22   -11.00          70.0           supermercados_70   \n",
       "...                ...      ...           ...                        ...   \n",
       "1482        2016-09-05  1533.02          18.0     retribucion_liquida_18   \n",
       "1483        2016-09-05  -617.47         126.0    liquidacion_tarjeta_126   \n",
       "1484        2016-09-05  -138.08         125.0                 cuotas_125   \n",
       "1485        2016-09-01   -32.22          90.0            seguro_salud_90   \n",
       "1486        2016-09-01   -33.00         434.0                 cuotas_434   \n",
       "\n",
       "      Nivel categoría  iD categoría padre Nombre categoría padre  \\\n",
       "0                 2.0                 5.0            vehiculos_5   \n",
       "1                 2.0                 8.0    gastos_personales_8   \n",
       "2                 2.0                 4.0         alimentacion_4   \n",
       "3                 3.0               521.0    Comunicaciones y TV   \n",
       "4                 2.0                 4.0         alimentacion_4   \n",
       "...               ...                 ...                    ...   \n",
       "1482              3.0               576.0                 Nómina   \n",
       "1483              3.0               478.0   tarjetas_credito_478   \n",
       "1484              3.0               127.0      otros_pasivos_127   \n",
       "1485              2.0                 6.0                salud_6   \n",
       "1486              3.0               115.0           deportes_115   \n",
       "\n",
       "                    Proveedor               Marca  \\\n",
       "0                         NaN                 NaN   \n",
       "1                         NaN                 NaN   \n",
       "2                        SPAR                SPAR   \n",
       "3                Jazz Telecom             Jazztel   \n",
       "4                   Mercadona           Mercadona   \n",
       "...                       ...                 ...   \n",
       "1482                      NaN                 NaN   \n",
       "1483                      NaN                 NaN   \n",
       "1484                      NaN                 NaN   \n",
       "1485  Sanitas S.A. de Seguros             Sanitas   \n",
       "1486       Royal Sport Center  Royal Sport Center   \n",
       "\n",
       "                            Sector  Financiero  Transferencia  Unnamed: 12  \\\n",
       "0                              NaN       False          False          NaN   \n",
       "1                              NaN       False          False          NaN   \n",
       "2                    Supermercados       False          False          NaN   \n",
       "3     Compañías telecomunicaciones       False          False          NaN   \n",
       "4                    Supermercados       False          False          NaN   \n",
       "...                            ...         ...            ...          ...   \n",
       "1482                           NaN       False          False          NaN   \n",
       "1483                           NaN        True           True          NaN   \n",
       "1484                           NaN        True          False          NaN   \n",
       "1485              Seguros de salud        True          False          NaN   \n",
       "1486              Clubs deportivos       False          False          NaN   \n",
       "\n",
       "      Unnamed: 13        ID  BALANCE BALANCE_DATE  \n",
       "0             NaN  249236.0  1478.98   2020-07-26  \n",
       "1             NaN       NaN      NaN          NaT  \n",
       "2             NaN       NaN      NaN          NaT  \n",
       "3             NaN       NaN      NaN          NaT  \n",
       "4             NaN       NaN      NaN          NaT  \n",
       "...           ...       ...      ...          ...  \n",
       "1482          NaN       NaN      NaN          NaT  \n",
       "1483          NaN       NaN      NaN          NaT  \n",
       "1484          NaN       NaN      NaN          NaT  \n",
       "1485          NaN       NaN      NaN          NaT  \n",
       "1486          NaN       NaN      NaN          NaT  \n",
       "\n",
       "[1487 rows x 17 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data using read_excel\n",
    "transacciones_df = read_excel('20210513 mmelero (249236).xlsx', sheet_name='Hoja1')\n",
    "transacciones_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e9c0cdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial log joint probability = -94.1071\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       1494.01    0.00121166       107.148      0.2422      0.2422      124   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     136       1503.56    0.00277982       182.636   8.621e-06       0.001      214  LS failed, Hessian reset \n",
      "     186       1509.76    0.00528468       94.6534    8.51e-05       0.001      316  LS failed, Hessian reset \n",
      "     199       1510.07   0.000252044       66.4183      0.3746           1      335   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       1514.96     0.0162046       122.668           1           1      457   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     377       1516.93   7.20644e-05       71.4779   1.063e-06       0.001      603  LS failed, Hessian reset \n",
      "     399       1516.94   3.98973e-06       61.5289           1           1      632   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     439       1516.95   0.000327375        70.191   3.579e-06       0.001      734  LS failed, Hessian reset \n",
      "     499       1516.96   3.51948e-07       62.0407           1           1      830   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     557        1517.1   0.000565253        71.979   8.974e-06       0.001      943  LS failed, Hessian reset \n",
      "     599       1517.15   3.68772e-07       65.7724      0.8906      0.8906     1004   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     609       1517.15   5.89422e-08       71.8297      0.4309      0.4309     1018   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "\n",
      "Tus gasto aproximado en supermercados en August-2020 sera: 205 eur\n",
      "Predicción válida: True\n",
      "True\n",
      "202.99492412315485\n",
      "2020\n",
      "8\n",
      "August\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def supermercardos_70(transacciones_df):\n",
    "    \n",
    "    # nos quedamos con la fecha en que nos dan los datos de las transacciones\n",
    "    last_date_obj = transacciones_df.loc[0, 'BALANCE_DATE']\n",
    "    \n",
    "    # nos quedamos con las transacciones de la categoría 'supermercados_70'\n",
    "    transacciones_super_df = transacciones_df[transacciones_df['ID Categoría'] == 70.0]\n",
    "    \n",
    "    # ya no necesitamos transacciones_df\n",
    "    del transacciones_df\n",
    "    \n",
    "    # nos quedamos con columnas desde 'Fecha transacción' hasta 'Importe'\n",
    "    transacciones_super_df = transacciones_super_df.iloc[:, 0:2]\n",
    "    \n",
    "    # renombramos columnas\n",
    "    transacciones_super_df.rename(columns={'Fecha transacción': 'FECHA', 'Importe': 'IMPORTE'}, inplace=True)\n",
    "    \n",
    "    # ordenamos las fechas por orden ascendente\n",
    "    transacciones_super_df.sort_values(by=['FECHA'], ascending=True, inplace=True, ignore_index=True)\n",
    "    \n",
    "    # vamos a agrupar los valores y sumarlos por fecha\n",
    "    transacciones_super_df = transacciones_super_df.groupby(['FECHA']).sum()\n",
    "    \n",
    "    # hacemos una columna con el indice\n",
    "    transacciones_super_df['FECHA'] = transacciones_super_df.index\n",
    "    \n",
    "    # sumamos la cuantía de las transacciones de cada mes y la suma la ponemos fecha del inicio de cada mes\n",
    "    transacciones_month_df = transacciones_super_df.groupby(pandas.Grouper(key='FECHA', freq=\"MS\")).sum()\n",
    "    \n",
    "    # ya no necesitamos transacciones_super_df\n",
    "    del transacciones_super_df\n",
    "    \n",
    "    # para que los datos sean más fáciles de interpretar vamos a hacerlos todos positivos multiplicándolos por '-1'\n",
    "    transacciones_month_df['IMPORTE'] = -transacciones_month_df['IMPORTE']\n",
    "    \n",
    "    # en transacciones_mfilled_df rellenaremos las fechas sin importe con el importe valido inmediatamente anterior\n",
    "    transacciones_mfilled_df = transacciones_month_df.copy()\n",
    "    \n",
    "    # ya no necesitamos transacciones_month_df\n",
    "    del transacciones_month_df\n",
    "    \n",
    "    # hacemos una columna con la fecha del indice\n",
    "    transacciones_mfilled_df['FECHA'] = transacciones_mfilled_df.index\n",
    "    \n",
    "    # indice de fechas hasta el ultimo dia del mes para el cual hay datos\n",
    "    idx = date_range(start=transacciones_mfilled_df.FECHA.min(), \n",
    "                     end=transacciones_mfilled_df.FECHA.max() + MonthEnd(1))\n",
    "    \n",
    "    # rellenamos las missing dates en el indice\n",
    "    transacciones_mfilled_df = transacciones_mfilled_df.reindex(idx, fill_value='NaN')\n",
    "    \n",
    "    # hacemos drop de la columna FECHA\n",
    "    transacciones_mfilled_df.drop(columns='FECHA', inplace=True)\n",
    "    \n",
    "    # pasamos IMPORTE a formato 'numeric'\n",
    "    transacciones_mfilled_ser = transacciones_mfilled_df.T.squeeze()    \n",
    "    transacciones_mfilled_ser = to_numeric(transacciones_mfilled_ser, errors='coerce')\n",
    "    transacciones_mfilled_df = DataFrame(transacciones_mfilled_ser)\n",
    "    del transacciones_mfilled_ser\n",
    "    \n",
    "    # rellenamos los NaN con el ultimo valor numérico anterior\n",
    "    transacciones_mfilled_df['IMPORTE'].fillna(method='ffill', inplace=True)\n",
    "    \n",
    "    # a continuación vamos a estimar con prophet la serie temporal del importe con los datos del dataframe\n",
    "    # 'transacciones_mfilled_df'.\n",
    "    # vamos a entrenar la serie desde el segundo mes de transacciones_mfilled_df hasta el penúltimo mes de\n",
    "    # transacciones_mfilled_df porque para el primer y ultimo mes de datos en ocasiones no se dispondrá del mes\n",
    "    # completo con lo que tenemos valores inferiores de IMPORTE para esos meses que distorsionan el calculo de la\n",
    "    # serie temporal\n",
    "    prophet_train_df = transacciones_mfilled_df.copy()\n",
    "    \n",
    "    # Time Series Forecasting With Prophet in Python\n",
    "    # https://machinelearningmastery.com/time-series-forecasting-with-prophet-in-python/\n",
    "    \n",
    "    # Fit Prophet Model\n",
    "    \n",
    "    # para los datos de training tenemos que quitar los datos del mes en el que pedimos la estimación.\n",
    "    # ya que si hacemos la estimación al principio del mes el gasto en supermercados sera mucho menor respecto al\n",
    "    # gasto en supermercados de un mes completo similar\n",
    "    \n",
    "    # hacemos una columna con el indice que se llame fecha\n",
    "    prophet_train_df['FECHA'] = prophet_train_df.index\n",
    "    \n",
    "    # calculamos el ultimo año\n",
    "    last_year = prophet_train_df['FECHA'].dt.year.max()\n",
    "    \n",
    "    # calculamos el ultimo mes del ultimo año\n",
    "    last_month = prophet_train_df[str(last_year)]['FECHA'].dt.month.max()\n",
    "    \n",
    "    # hacemos un string con el ultimo año y mes para hacer una mascara\n",
    "    last_year_month = str(last_year) + '-' + str(last_month)\n",
    "    \n",
    "    # calculamos la fecha maxima para quitarnos las transacciones en fecha iguales o posterior a esta\n",
    "    maximum_date_obj = prophet_train_df[last_year_month]['FECHA'].min()\n",
    "    \n",
    "    # hacemos una mascara para quitar las filas del ultimo mes\n",
    "    before_maximum_date_ser = prophet_train_df['FECHA'] < maximum_date_obj\n",
    "    \n",
    "    # aplicamos la mascara\n",
    "    prophet_train_df = prophet_train_df.loc[before_maximum_date_ser]\n",
    "    \n",
    "    # también tenemos que quitar del dataframe los datos del primer mes porque también puede estar no completo y\n",
    "    # nos desvirtúa también la serie temporal del entrenamiento\n",
    "    \n",
    "    # calculamos el primer año del dataframe\n",
    "    first_year = prophet_train_df['FECHA'].dt.year.min()\n",
    "    \n",
    "    # calculamos el primer mes del primer año\n",
    "    first_month = prophet_train_df[str(first_year)]['FECHA'].dt.month.min()\n",
    "    \n",
    "    # hacemos un string con el primer mes del primer año para hacer una mascara\n",
    "    first_year_month = str(first_year) + '-' + str(first_month)\n",
    "    \n",
    "    # calculamos la fecha minima para quedarnos con todas las transacciones del dataframe posteriores a esa fecha\n",
    "    minimum_date_obj = prophet_train_df[first_year_month]['FECHA'].max()\n",
    "    \n",
    "    # hago una mascara para quitar las filas del primer mes\n",
    "    after_minimum_date_ser = prophet_train_df['FECHA'] > minimum_date_obj\n",
    "    \n",
    "    # aplicamos la mascara anterior\n",
    "    prophet_train_df = prophet_train_df.loc[after_minimum_date_ser]\n",
    "    \n",
    "    # reordenamos las columnas de prophet_train_df\n",
    "    prophet_train_df = prophet_train_df[['FECHA', 'IMPORTE']]\n",
    "    \n",
    "    # prepare expected column names\n",
    "    prophet_train_df.columns = ['ds', 'y']\n",
    "    \n",
    "    # reseteamos el indice del dataframe\n",
    "    prophet_train_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # define the model\n",
    "    model = Prophet()\n",
    "    \n",
    "    # fit the model\n",
    "    model.fit(prophet_train_df)\n",
    "    \n",
    "    # vamos a pedirle a prophet que haga la predicción hasta el ultimo dia del mes siguiente al de 'last_date_obj'\n",
    "    future_out_sample = transacciones_mfilled_df.copy()\n",
    "    \n",
    "    # hacemos una columna 'FECHA' con el indice\n",
    "    future_out_sample['FECHA'] = future_out_sample.index\n",
    "    \n",
    "    # hacemos un drop de la columna 'IMPORTE'\n",
    "    future_out_sample.drop(columns='IMPORTE', inplace=True)\n",
    "    \n",
    "    # calculamos la fecha del ultimo dia \n",
    "    target_date_obj = last_date_obj + DateOffset(months=1) + MonthEnd(1)\n",
    "    \n",
    "    # calculamos el rango de fechas de la estimación\n",
    "    idx = date_range(start=prophet_train_df.ds.min(), end=target_date_obj)\n",
    "    \n",
    "    # rehacemos el indice de future_out_sample de acuerdo a las fechas de idx\n",
    "    future_out_sample = future_out_sample.reindex(idx)\n",
    "    \n",
    "    # hacemos una columna con el nuevo indice\n",
    "    future_out_sample.reset_index(drop=False, inplace=True)\n",
    "    \n",
    "    # hacemos un drop de la columna 'FECHA'\n",
    "    future_out_sample.drop(columns='FECHA', inplace=True)\n",
    "    \n",
    "    # renombramos la columna del dataframe a 'ds'\n",
    "    future_out_sample.columns = ['ds']\n",
    "    \n",
    "    # use the model to make a forecast\n",
    "    forecast_df = model.predict(future_out_sample)\n",
    "    \n",
    "    # nos quedamos con las columnas 'ds' y 'yhat'\n",
    "    forecast_df = forecast_df[['ds', 'yhat']]\n",
    "    \n",
    "    # nos quedamos con las filas del ultimo mes que es para el que hemos hecho la predicción\n",
    "    # calculamos el ultimo año\n",
    "    last_year = forecast_df['ds'].dt.year.max()\n",
    "    \n",
    "    # calculamos el ultimo mes del ultimo año creándonos un dataframe donde al final tendremos la estimación del\n",
    "    # ultimo mes\n",
    "    prediction_df = forecast_df.copy()\n",
    "    \n",
    "    # rehacemos el indice con la FECHA columna 'ds'\n",
    "    prediction_df.set_index('ds', drop=False, inplace=True)\n",
    "    \n",
    "    # calculamos el ultimo mes del ultimo año\n",
    "    last_month = prediction_df[str(last_year)]['ds'].dt.month.max()\n",
    "    \n",
    "    # hago una variable str con el ultimo año y el ultimo mes\n",
    "    last_year_month = str(last_year) + '-' + str(last_month)\n",
    "    \n",
    "    # calculo la fecha minima a partir de la cual me quedo con los datos\n",
    "    minimum_date_obj = prediction_df[last_year_month]['ds'].min()\n",
    "    \n",
    "    # hago una mascara para quedarme con las filas del ultimo año y del ultimo mes\n",
    "    after_minimum_date_ser = prediction_df['ds'] >= minimum_date_obj\n",
    "    \n",
    "    # aplico la mascara para quedarme finalmente con las filas de las transacciones del ultimo mes y del ultimo año\n",
    "    prediction_df = prediction_df.loc[after_minimum_date_ser]\n",
    "    \n",
    "    # hacemos un drop de la columna con las fechas\n",
    "    prediction_df.drop(columns='ds', inplace=True)\n",
    "    \n",
    "    # damos la predicción final como la media de valores predichos para el mes\n",
    "    final_prediction = float(prediction_df.mean())\n",
    "    \n",
    "    # a continuación comprobamos que la media de transacciones en supermercado desde el dia 1 del mes anterior es\n",
    "    # mayor que 0 para poder dar la predicción como valida \n",
    "    \n",
    "    # calculamos la fecha del primer dia del mes anterior a la petición\n",
    "    target_date_obj = last_date_obj - DateOffset(months=1) - MonthBegin(1)\n",
    "    \n",
    "    # hago una mascara para solo quedarme con las filas del dataframe a partir de target_date_obj\n",
    "    after_target_date_ser = transacciones_mfilled_df.index >= target_date_obj\n",
    "    \n",
    "    # aplico la mascara\n",
    "    final_mean_df = transacciones_mfilled_df.loc[after_target_date_ser]\n",
    "    \n",
    "    # calculo la media final desde el dia 1 del mes anterior a la petición\n",
    "    final_mean = float(final_mean_df.mean())\n",
    "    \n",
    "    # hago el chequeo final de que la predicción sea valida\n",
    "    valid_prediction = False\n",
    "\n",
    "    if final_mean != 0:\n",
    "        valid_prediction = True\n",
    "    elif float(final_prediction) == 0:\n",
    "        valid_prediction = True\n",
    "        \n",
    "    # hago un dataframe para calcular el año y mes de la predicción\n",
    "    final_date_month_df = prediction_df.copy()\n",
    "    \n",
    "    # hacemos una columna con el indice\n",
    "    final_date_month_df.reset_index(inplace=True)\n",
    "    \n",
    "    # calculo el año de la predicción\n",
    "    final_year = final_date_month_df['ds'].dt.year.max()\n",
    "    \n",
    "    # calculo el mes de la predicción\n",
    "    final_month = final_date_month_df['ds'].dt.month.max()\n",
    "    \n",
    "    # paso de numero a nombre el mes de la predicción\n",
    "    datetime_object = datetime.strptime(str(final_month), \"%m\")\n",
    "    final_month_str = datetime_object.strftime(\"%B\")\n",
    "    \n",
    "    # damos resultados finales\n",
    "#     print('Tus gasto aproximado en supermercados en ' + final_month_str + '-' + str(final_year) +\n",
    "#           ' sera: ' + str(5 * round(final_prediction / 5)) + ' eur')\n",
    "    mensaje1_str = 'Tus gasto aproximado en supermercados en ' + final_month_str + '-' + str(\n",
    "        final_year) + ' sera: ' + str(5 * round(final_prediction / 5)) + ' eur'\n",
    "#     print('Predicción válida: ' + str(valid_prediction))    \n",
    "    mensaje2_str = 'Predicción válida: ' + str(valid_prediction)\n",
    "    \n",
    "#     print(last_date_obj)\n",
    "#     print(transacciones_super_df)\n",
    "#     print(transacciones_month_df)\n",
    "#     print(transacciones_mfilled_df)\n",
    "#     print(transacciones_mfilled_ser)\n",
    "#     print(idx)\n",
    "#     print(prophet_train_df)\n",
    "#     print(last_year)\n",
    "#     print(last_month)\n",
    "#     print(last_year_month)\n",
    "#     print(maximum_date_obj)\n",
    "#     print(before_maximum_date_ser)\n",
    "#     print(first_year)\n",
    "#     print(first_month)\n",
    "#     print(first_year_month)\n",
    "#     print(minimum_date_obj)\n",
    "#     print(after_minimum_date_ser)\n",
    "#     print(future_out_sample)\n",
    "#     print(target_date_obj)    \n",
    "#     model.plot(forecast_df)\n",
    "#     pyplot.show()\n",
    "#     print(forecast_df)\n",
    "#     print(prediction_df)\n",
    "#     print(final_prediction)\n",
    "#     print(after_target_date_ser)\n",
    "#     print(final_mean_df)\n",
    "#     print(final_mean)\n",
    "#     print(valid_prediction)\n",
    "#     print(final_date_month_df)\n",
    "#     print(final_year)\n",
    "#     print(final_month)\n",
    "#     print(final_month_str)\n",
    "    \n",
    "    return mensaje1_str, mensaje2_str, valid_prediction, final_prediction, final_year, final_month, final_month_str\n",
    "\n",
    "# Load data using read_excel\n",
    "transacciones_orig_df = read_excel('20210513 mmelero (249236).xlsx', sheet_name='Hoja1')\n",
    "\n",
    "mensaje1, mensaje2, valid_prediction, final_amount, final_year, final_month, final_month_str = supermercardos_70(\n",
    "    transacciones_orig_df)\n",
    "\n",
    "print()\n",
    "print(mensaje1)\n",
    "print(mensaje2)\n",
    "print(valid_prediction)\n",
    "print(final_amount)\n",
    "print(final_year)\n",
    "print(final_month)\n",
    "print(final_month_str)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4786211f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
